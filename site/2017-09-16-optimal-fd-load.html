<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2017-09-16" />
  <title>Optimal failure detector performance</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <script>
  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('.zippy').forEach(zippy => {
      const previewText = zippy.getAttribute('data-preview') || 'Click to expand';
      zippy.innerHTML = `
        <div class="zippy-header-collapsed">${previewText} ▶</div>
        <div class="zippy-header-expanded">${previewText} ▼</div>
        <div class="zippy-content">${zippy.innerHTML}</div>
      `;

      zippy.addEventListener('click', function() {
        this.classList.toggle('expanded');
      });
    });
  });
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<nav id="mainnav">
  <a href="index.html">Home</a>
</nav>
<header id="title-block-header">
<h1 class="title">Optimal failure detector performance</h1>
<p class="date">2017-09-16</p>
</header>
<p>This is a note to self on computing the lower bound on number of
messages each process in a distributed failure detector must send to
guarantee adherence to pre-specified values for:</p>
<ul>
<li>Time to first detection of a true failure.</li>
<li>False positive detection rate.</li>
<li>Message loss rate.</li>
</ul>
<p>In other words, the failure detector accepts as parameters the above
three values, and for those guarantees to be respected, each node in the
failure detector cluster must send at least <span
class="math inline">\(m\)</span> number of messages, which is what we
are after.</p>
<p>The original paper from which I learnt most of this is <a
href="http://www.cs.cornell.edu/projects/quicksilver/public_pdfs/On%20Scalable.pdf">On
Scalable and Efficient Distributed Failure Detectors</a>.</p>
<p>We shall talk about eventually complete (<em>every</em> failure is
eventually detected) failure detection, in a crash-stop failure model
(actually it isn’t hard to extend the analysis to a crash-recovery
model, but we don’t assume Byzantine failures).</p>
<h2 id="parameters">Parameters</h2>
<h3 id="time-to-first-detection-of-a-true-failure">1. Time to first
detection of a true failure</h3>
<p>The failure detector in question accepts a parameter <span
class="math inline">\(T\)</span>, which is the maximum time in seconds
between a process failing, and <em>some</em> other process detecting
this. Note that this explicitly does <em>not</em> assume any
dissemination mechanism, and depending on what it is, <em>first</em>
detection may or may not mean detection by all non-faulty processes.</p>
<h3 id="false-positive-detection-rate">2. False positive detection
rate</h3>
<p>The next parameter the failure detector accepts is <span
class="math inline">\(\alpha_{T}\)</span>, the acceptable false failure
detection rate till the first true failure detection. This is a bit
tricky to understand. Consider at time <span
class="math inline">\(t_0\)</span>, we have a bunch of non-faulty
processes <span class="math inline">\(p_1, p_2, p_3.., p_M\)</span> that
have not been marked failed yet. We want the probability that any
<em>non faulty</em> process marks any of <span
class="math inline">\(p_i\)</span> as failed till <span
class="math inline">\(t_0 + T\)</span> to be capped at <span
class="math inline">\(\alpha_{T}\)</span>. To look at this from another
perspective, consider 1000 random time periods, each of length <span
class="math inline">\(T\)</span>. For each time period, we count the
number of false failure detections, and sum them up (good nodes marked
as faulty by another good node). We want this number to be no more than
<span class="math inline">\(1000\alpha_T\)</span>.</p>
<h3 id="message-loss-rate">3. Message loss rate</h3>
<p>The application also specifies the probability of any given message
being lost. This is applied independently to each message, and hence may
not be a true picture of what happens in the real world (correlated
message losses around congested network zones), but hey at least <a
href="http://abstrusegoose.com/406">we are not talking about a spherical
cow in vaccum</a>. We call this parameter <span
class="math inline">\(p_{ml}\)</span>.</p>
<h2 id="result">Result</h2>
<p>With the parameters specified as above, in an <span
class="math inline">\(N\)</span> node distributed failure detector, the
<em>minimum</em> number of messages each node has to send per second is
given by</p>
<p><span class="math display">\[
    m_{min} = \frac{1}{T} \frac{\log\alpha_T}{\log{p_{ml}}}
\]</span></p>
<p>This is neat, because it does not depend on the cluster size <span
class="math inline">\(N\)</span>!</p>
<h2 id="proof">Proof</h2>
<p>Suppose each node sends <span class="math inline">\(m\)</span>
messages out (as heartbeats or pings to other nodes) in a time period
<span class="math inline">\(T\)</span>. The only way a non-faulty
process can appear as faulty to all others is if <em>all</em> its
outgoing messages are dropped in the time-period of <span
class="math inline">\(T\)</span> seconds. This happens with probability
<span class="math inline">\(\left(p_{ml}\right)^m\)</span>. We want this
probability to be capped at <span
class="math inline">\(\alpha_T\)</span>. So,</p>
<p><span class="math display">\[
\alpha_T \ge \left(p_{ml}\right)^m
\]</span></p>
<p><span class="math display">\[
\implies \log{\alpha_T} \ge m\log{p_{ml}}
\]</span></p>
<p><span class="math display">\[
\implies m  \ge \frac{\log\alpha_T}{\log{p_{ml}}}
\left(\because 0 \lt p_{ml}
\lt 1, 0 \lt \alpha_T \lt 1 \right)
\]</span></p>
<p>Since <span class="math inline">\(m\)</span> is the number of
messages sent <em>every T seconds</em>, the number of messages per
second <span class="math inline">\(m_r \ge \frac{1}{T}
\frac{\log\alpha_T}{\log{p_{ml}}}\)</span>, and hence, <span
class="math inline">\(m_{min} = \frac{1}{T}
\frac{\log\alpha_T}{\log{p_{ml}}}\)</span>.</p>
</body>
</html>
