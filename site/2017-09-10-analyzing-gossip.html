<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2017-09-10" />
  <title>Analysis of gossip based dissemination</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <script>
  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('.zippy').forEach(zippy => {
      const previewText = zippy.getAttribute('data-preview') || 'Click to expand';
      zippy.innerHTML = `
        <div class="zippy-header-collapsed">${previewText} ▶</div>
        <div class="zippy-header-expanded">${previewText} ▼</div>
        <div class="zippy-content">${zippy.innerHTML}</div>
      `;

      zippy.addEventListener('click', function() {
        this.classList.toggle('expanded');
      });
    });
  });
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<nav id="mainnav">
  <a href="index.html">Home</a>
</nav>
<header id="title-block-header">
<h1 class="title">Analysis of gossip based dissemination</h1>
<p class="date">2017-09-10</p>
</header>
<p>Gossip based protocols are widely used in distributed systems for
robust dissemination of information. The problem: spreading a message
among a set of processes. For example, in the Bitcoin P2P network,
whenever a new transaction happens, it needs to be broadcast to all
peers in order for it to end up on the blockchain. Typically, such
information originates at one of the nodes in the network, and needs to
be communicated to the rest of the peers.</p>
<p>One elegant solution to this problem mimics how rumours spread in the
society by word of mouth, namely “gossip” based protocols. The gossip
component of every non-faulty process in the network maintains two main
pieces of state: a list of other known live peers, and a buffer of
recent messages. Then every <code>T</code> seconds, (called the
<em>gossip period</em>), every node executes the following:</p>
<ol type="1">
<li>Pick <code>f</code> peers from the membership list at random. Here,
<code>f</code> is called the gossip fanout.</li>
<li>Send recent messages from our messages buffer to each of these
peers.</li>
</ol>
<p>Of course, in parallel, each node must listen for messages and update
its message buffer.</p>
<p>The details like the value of the gossip fanout, and what exact
messages to relay, and for how many rounds, etc. are what make different
gossip protocols different, but we aren’t going to talk much about it
here.</p>
<h2 id="analysis">Analysis</h2>
<p>The analysis focuses on finding upper bounds for:</p>
<ul>
<li>The number of rounds needed to get an update to all
participants.</li>
<li>The load on each participating peer.</li>
</ul>
<p>To begin with, we note that the inherent random nature of the
algorithm means that we can only comment about the <em>expected</em>
behaviour of the protocol — i.e., we are after the number of rounds that
a cluster of <code>N</code> nodes needs to have a message disseminated
across the cluster <em>with high probability</em>.</p>
<h3 id="dissemination-time">Dissemination time</h3>
<p>This refers to the number of gossip rounds before we can be
reasonably sure about a message having been disseminated across the
cluster.</p>
<p>This analysis is borrowed (indirectly) from work on epidemiology —
our problem is not so different from a situation where an infected
organism comes in contact with random uninfected individuals, thereby
infecting them. These individuals in turn go on to infect others and so
on.</p>
<p>For our purpose, we shall say that a node in possession of a
particular message <code>M</code> is “infected”, while nodes which don’t
know about <code>M</code> yet are uninfected. Let’s further suppose that
after round <code>T</code>, <code>x</code> nodes are still uninfected,
and <code>y</code> nodes are infected. Of course, at <code>T=0</code>,
<code>x=N-1</code>, and <code>y=1</code> (i.e., we have one “infected”
node that knows of the message <code>M</code> and is now out to infect
others with this knowledge). Now because each node picks <code>f</code>
others at random to gossip with, and because the proportion of
uninfected nodes in the cluster is <span
class="math inline">\(\frac{x}{N}\)</span>, on average any given
infected node will pick <span
class="math inline">\(\frac{x}{N}f\)</span> uninfected nodes. Since
there are <span class="math inline">\(y\)</span> such infected nodes, on
average, we’ll see <span class="math inline">\(\frac{f}{N}xy\)</span>
infected-uninfected interactions in a round. Since an uninfected node
turns into an infected node after receiving the message <code>M</code>,
on average, each round results in a <em>decrease</em> in the number of
uninfected nodes (<span class="math inline">\(x\)</span>) by this
quantity <span class="math inline">\(\frac{f}{N}xy\)</span>.
Therefore,</p>
<p><span class="math display">\[
\frac{dx}{dT} = -\frac{f}{N}xy
\]</span></p>
<p>Let $ = $</p>
<p>Then,</p>
<p><span class="math display">\[
\begin{align*}
\frac{dx}{dT} &amp;= -\beta xy \\\\
\implies \frac{dx}{dT} &amp;= -\beta x\left(N-x\right) \\\\
\implies \frac{dx}{x\left(N-x\right)} &amp;= -\beta dT \\\\
\implies \int \frac{dx}{x\left(N-x\right)} &amp;= -\beta \int dT
\tag{eqn1} \label{eqn1}
\end{align*}
\]</span></p>
<p>Let <span class="math inline">\(\frac{1}{x\left(N-x\right)} =
\frac{A}{x} + \frac{B}{N-x} \implies A\left(N-x\right) + Bx =
1\)</span>.</p>
<p>Now setting <span class="math inline">\(x=0 \implies A =
\frac{1}{N}\)</span>, and setting <span class="math inline">\(x=N
\implies
B = \frac{1}{N}\)</span>. Using this in <span
class="math inline">\(\eqref{eqn1}\)</span>, we have</p>
<p><span class="math display">\[
\begin{align*}
\frac{1}{N}\int \frac{dx}{x} + \frac{1}{N} \int \frac{dx}{N-x}  &amp;=
-\beta \int dT \\\\
\implies \frac{1}{N} \left( \ln{x} - \ln{\left(N-x\right)} \right) + C
&amp;= -\beta T \tag{eqn2} \label{eqn2}
\end{align*}
\]</span></p>
<p>Where <span class="math inline">\(C\)</span> is the constant of
integration. To find it, we note that at <span
class="math inline">\(T=0,
x=N-1\)</span>. Using this in <span
class="math inline">\(\eqref{eqn2}\)</span>, we find that <span
class="math inline">\(C=-\frac{ln\left(N-1\right)}{N}\)</span>.
Substituting this value for <span class="math inline">\(C\)</span> in
<span class="math inline">\(\eqref{eqn2}\)</span> then yields:</p>
<p><span class="math display">\[
\begin{align*}
\frac{1}{N} \left( \ln{x} - \ln{\left(N-x\right)} -
\ln{\left(N-1\right)} \right) &amp;= -\beta T \\\\
\implies \ln{\frac{x}{N-x}} - \ln{\left(N-1\right)} &amp;= -N\beta T
\\\\
\implies \ln{\frac{x}{N-x}}  &amp;= -N\beta T + \ln{\left(N-1\right)}
\\\\
\implies \frac{x}{N-x} &amp;= e^{-N\beta T + \ln{\left(N-1\right)} } =
\left(N-1\right)e^{-N\beta T}  \\\\
\implies \frac{N-x}{x} &amp;= {e^{N\beta T}\over N-1} \\\\
\implies \frac{N}{x} &amp;= 1 + {e^{N\beta T}\over N-1} \\\\
\implies \frac{x}{N} &amp;= {1\over {1 + {e^{N\beta T}\over N-1}}} =
\frac{N-1}{N-1+e^{N\beta T}} \\\\
\end{align*}
\]</span></p>
<p>So, as <span class="math inline">\(T\)</span> (number of gossip
rounds) grows, the expected value of the fraction <span
class="math inline">\(x\over N\)</span> of uninfected nodes rapidly
approaches zero. Since the number of <em>infected</em> nodes <span
class="math inline">\(y=N-x\)</span>, we have the proportion of
uninfected nodes</p>
<p><span class="math display">\[
\begin{align*}
{y\over N} &amp;= 1 - {x\over N} \\\\
&amp;= 1 - \frac{N-1}{N-1+e^{N\beta T}} \\\\
&amp;= \frac{e^{N\beta T}}{N-1+e^{N\beta T}}
\end{align*}
\]</span></p>
<p>As we grow <span class="math inline">\(T\to\infty\)</span>,</p>
<p><span class="math display">\[
\begin{align*}
\lim_{T\to\infty}\frac{e^{N\beta T}}{N-1+e^{N\beta T}} &amp;= \\\\
&amp;= \lim_{T\to\infty}\frac{1}{\frac{N-1}{e^{N\beta T}}+1} \\\\
&amp;= \frac{1}{\lim_{T\to\infty}\frac{N-1}{e^{N\beta T}}+1} \\\\
&amp;= \frac{1}{0+1} \\\\
&amp;= 1
\end{align*}
\]</span></p>
<p>Hence the expected proportion of infected nodes reaches 100% as the
protocol keeps running. But this begs the question, how long in practice
do we have to wait before the whole cluster gets the new message with
high probability? Let’s call <span
class="math inline">\(T_{1\over2}\)</span> the number of rounds when
<em>half</em> of the cluster gets the update, i.e., at <span
class="math inline">\(T=T_{h}\)</span>, <span
class="math inline">\(\frac{x}{N}=\frac{y}{N}=\frac{1}{2}\)</span>.
Therefore, from the expression for <span
class="math inline">\(\frac{x}{N}\)</span> above,</p>
<p><span class="math display">\[
\begin{align*}
\frac{1}{2} &amp;= \frac{N-1}{N-1+e^{N\beta T_{h}}} \\\\
\implies e^{N\beta T_{h}} &amp;= N-1 \\\\
\implies N\beta T_h &amp;= \ln\left({N-1}\right) \\\\
\implies T_h &amp;= \frac{1}{N\beta}\ln\left({N-1}\right)
\end{align*}
\]</span></p>
<p>Now using <span class="math inline">\(\beta = {f\over N}\)</span>, we
get <span class="math inline">\(T_h = \frac{1}{f}\ln{\left(N-1\right)}
= O\left(\ln{N}\right)\)</span>. Hence, the half life of the process is
logarithmic in the number of participants <span
class="math inline">\(N\)</span>. Now, to find the number of rounds it
takes for <span class="math inline">\(99\%\)</span> of the uninfected
nodes to befome infected can be computed as:</p>
<p><span class="math display">\[
\begin{align*}
\frac{N-1}{N-1+e^{N\beta T_{0.99}}} = 0.99 \\\\
\implies N\beta T_{0.99} &amp;= \ln\left(\frac{N-1}{9}\right) \\\\
\implies  T_{0.99} &amp;= {\ln\left(\frac{N-1}{9}\right) \over N\beta }
= O\left(\ln{N}\right)\\\\
\end{align*}
\]</span></p>
<p>So we see that within a logarithmic number of rounds, a <em>most</em>
of the nodes get infected with high probability.</p>
<h3 id="message-load-per-member">Message load per member</h3>
<p>A dissemination mechanism is no good if it puts unreasonable load on
member nodes, and/or fails to spread out the load evenly across the
cluster. In gossip based dissemination, each node sends out <span
class="math inline">\(f\)</span> messages, and receives on expectation
<span class="math inline">\(f\over N\)</span> messages <em>per
round</em>. Since <span
class="math inline">\(\Theta\left(\ln{N}\right)\)</span> rounds are
needed for a message to get to the whole cluster, the load on each node
is also logarithmic in <span class="math inline">\(N\)</span>, and every
node has similar load. This is quite nice, since one can grow the
cluster to very huge sizes, and even then the load on each node remains
reasonably low.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Gossip based protocols are amazingly simple and robust, which is why
they form crucial elements of failure detection and membership layers of
many large scale distributed systems. Note that I did not talk about
nodes failing in this post, and the focus was on the use of gossip for
dissemination. However, gossip itself can be used to implement failure
detectors, like the <a
href="https://www.cs.cornell.edu/~asdas/research/dsn02-swim.pdf">SWIM
failure detector</a>(very readable paper). Here, every node periodically
gossips cluster membership updates. The protocol is augmented with
several features like acknowledgements and indirect acknowledgements
allows the failure detector to scale with tunable false positive
characteristics.</p>
</body>
</html>
